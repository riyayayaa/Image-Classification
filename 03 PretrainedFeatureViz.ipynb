{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROR2D7pUF62A"
      },
      "source": [
        "## In this code we are going to load pretrained image classification networks\n",
        "- ResNet50\n",
        "- VGG16\n",
        "- VGG19\n",
        "\n",
        "## Then using a **pretrained network**, **feature extraction** and visualization is conducted via **t-SNE**\n",
        "\n",
        "![deepnets](https://imgur.com/nyYh5xH.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NLeJNPl32ez4"
      },
      "outputs": [],
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8szE6F7O2sUe"
      },
      "outputs": [],
      "source": [
        "!wget -nv https://images.immediate.co.uk/production/volatile/sites/4/2018/08/iStock_000044061370_Medium-fa5f8aa.jpg -O cat.jpg\n",
        "\n",
        "img = Image.open('./cat.jpg')\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBpnuCHu27KT"
      },
      "source": [
        "## Classify ImageNet classes with ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvkG-Axe2sZB"
      },
      "outputs": [],
      "source": [
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "img_path = './cat.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "print('image.img_to_array: ', x.shape, np.max(x), np.min(x))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "print('expand_dims: ', x.shape, np.max(x), np.min(x))\n",
        "x = preprocess_input(x)\n",
        "print('preprocess_input: ', x.shape, np.max(x), np.min(x))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKAINE7y2siC"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUNx4hvo3a6d"
      },
      "source": [
        "## Extract features with VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPUDG_Yk2srR"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlQUGW1n2swi"
      },
      "outputs": [],
      "source": [
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "features = model.predict(x)\n",
        "print(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXvaJ5GZ4COe"
      },
      "source": [
        "## Use VGG to extract features for arbitrary CIFAR-10 images\n",
        "\n",
        "![CIFAR-10](https://i2.wp.com/appliedmachinelearning.blog/wp-content/uploads/2018/03/cifar2.jpg?resize=427%2C325&ssl=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPL-hXpR2suU"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eygXuamE2spB"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "y_test_indx = np.squeeze(y_test)\n",
        "\n",
        "x_test = x_test[y_test_indx < 3]\n",
        "y_test = y_test[y_test_indx < 3]\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "print('y_test.shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzg0J5AL2snz"
      },
      "outputs": [],
      "source": [
        "# plot samples\n",
        "for i in range(9):\n",
        "\tplt.subplot(330 + 1 + i)\n",
        "\tplt.imshow(x_test[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDxJ90_V2sf4"
      },
      "outputs": [],
      "source": [
        "x = preprocess_input(x_test)\n",
        "\n",
        "features = model.predict(x)\n",
        "print(features.shape)\n",
        "feats = np.squeeze(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpAa4oti52kg"
      },
      "outputs": [],
      "source": [
        "# t-SNE\n",
        "tsne = TSNE(n_components=2, perplexity=30, verbose=2).fit_transform(feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i4c3sWv2scj"
      },
      "outputs": [],
      "source": [
        "y_test_color = np.squeeze(y_test)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.scatter(tsne[:, 0], tsne[:, 1], c=y_test_color)\n",
        "\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Acd9BYut2sWz"
      },
      "outputs": [],
      "source": [
        "# http://alexanderfabisch.github.io/t-sne-in-scikit-learn.html\n",
        "def plot_dataset(X, y, X_embedded, name, min_dist=10.0):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = plt.axes(frameon=False)\n",
        "    plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.9,\n",
        "                    wspace=0.0, hspace=0.0)\n",
        "\n",
        "    plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y)\n",
        "    if min_dist is not None:\n",
        "        from matplotlib import offsetbox\n",
        "        shown_images = np.array([[15., 15.]])\n",
        "        indices = np.arange(X_embedded.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        for i in indices[:5000]:\n",
        "            dist = np.sum((X_embedded[i] - shown_images) ** 2, 1)\n",
        "            if np.min(dist) < min_dist:\n",
        "                continue\n",
        "            shown_images = np.r_[shown_images, [X_embedded[i]]]\n",
        "            imagebox = offsetbox.AnnotationBbox(\n",
        "                offsetbox.OffsetImage(X[i].reshape(32, 32, 3)), X_embedded[i])\n",
        "            ax.add_artist(imagebox)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvAoDi-P42Du"
      },
      "outputs": [],
      "source": [
        "plot_dataset(x_test[:150], y_test_color[:150], tsne[:150], \"t-SNE\", min_dist=20.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U14qCPeN5DtE"
      },
      "source": [
        "## Extract features from an arbitrary intermediate layer with VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXPpDndM42HE"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "base_model = VGG19(weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3mAQUU-5HWF"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwKd3VA75HZC"
      },
      "outputs": [],
      "source": [
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "block4_pool_features = model.predict(x)\n",
        "print(block4_pool_features.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03 PretrainedFeatureViz .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}